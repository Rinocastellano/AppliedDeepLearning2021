{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m7cuRoUW5hmD"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import Input\n",
    "from matplotlib import pyplot\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uchZddi85oRD",
    "outputId": "7e8c73d7-b033-4282-8184-eb5c1dc73715"
   },
   "outputs": [],
   "source": [
    "#If you didn't run the previous code that do the preprocessing -> run this part of code please\n",
    "#DATASET USED FOR THE MODEL FOR TEMPO ESTIMATION\n",
    "!gdown --id 1nzep5kiiLNjjoFgoMa-gvLSbIQIr18yP\n",
    "!gdown --id 1GemCMmnmkiubcf77Q_uD4xuM90k7rGkx\n",
    "\n",
    "path=['Image_spec_key.zip','Annotations_key.zip']\n",
    "path_images=[\"Image_spec_key/GS\",\"Image_spec_key/GTZAN\"]\n",
    "path_ann=[\"Annotations_key/GS\",\"Annotations_key/GTZAN\"]\n",
    "from zipfile import ZipFile\n",
    "for p in path:\n",
    "    with ZipFile(p, 'r') as zipp:\n",
    "        # printing all the contents of the zip file\n",
    "        #zip.printdir()\n",
    "        print('Extracting all the files now...')\n",
    "        zipp.extractall()\n",
    "        print('Done!')\n",
    "flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DpDOruI06Jta"
   },
   "outputs": [],
   "source": [
    "#If you have done the preprocessing using the previous notebook, please run this part of code\n",
    "path_images=[\"Dataset/Key/GS/Image_spec\",\"Dataset/Key/GTZAN/Image_spec\"]\n",
    "path_ann=[\"Dataset/Key/GS/Ann\",\"Dataset/Key/GTZAN/Ann\"]\n",
    "flag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6L84lF36VdE",
    "outputId": "9342df9e-d04b-45f3-978f-b71d6e27406f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GS/1004923.LOFI_1.txt' 'GS/1004923.LOFI_2.txt' 'GS/1004923.LOFI_3.txt'\n",
      " ... 'GTZAN/rock.00098_2.txt' 'GTZAN/rock.00099_1.txt'\n",
      " 'GTZAN/rock.00099_2.txt']\n",
      "[]\n",
      "Sorting both images and annotations...\n",
      "GS/1004923.LOFI_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-e8057eff73bb>:30: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res=np.where(f_i==f\"{str(s)}.h5\")\n",
      "<ipython-input-6-e8057eff73bb>:31: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if(n==res[0]):\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e8057eff73bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_train_test_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_ann\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-e8057eff73bb>\u001b[0m in \u001b[0;36msplit_train_test_validation\u001b[1;34m(path_label, path_img)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "def split_train_test_validation(path_label,path_img):\n",
    "    f_l=[]\n",
    "    f_i=[]\n",
    "\n",
    "\n",
    "    for i,l in zip(path_images,path_ann):\n",
    "        f_l.extend([os.path.join(root, name) for root, dirs, files in os.walk(l) for name in files if name.endswith((\".txt\"))])\n",
    "        f_i.extend([os.path.join(root, name) for root, dirs, files in os.walk(i) for name in files if name.endswith((\".h5\"))]) \n",
    "\n",
    "    if flag==0:\n",
    "\n",
    "        f_l=[os.path.join(f.split('/')[1],f.split('/')[2]) for f in f_l]\n",
    "        f_i=[os.path.join(f.split('/')[1],f.split('/')[2]) for f in f_i]\n",
    "    if flag==1:\n",
    "        f_l=[f.split('/')[2]+\"/\"+(f.split('/')[-1]).split('\\\\')[1] for f in f_l]\n",
    "        f_i=[f.split('/')[2]+\"/\"+(f.split('/')[-1]).split('\\\\')[1] for f in f_i]\n",
    "    f_l= np.asarray(f_l)\n",
    "    f_i= np.asarray(f_i)\n",
    "    print(f_l)\n",
    "    print(f_i)\n",
    "    print(\"Sorting both images and annotations...\")\n",
    "    for n in range(f_l.shape[0]):\n",
    "        while True:\n",
    "            \n",
    "            s=splitext(f_l[n])[0]\n",
    "            #print(s)\n",
    "            if \"lerch\" in s:\n",
    "                s=s[:len(s)-6]\n",
    "\n",
    "            res=np.where(f_i==f\"{str(s)}.h5\")\n",
    "            if(n==res[0]):\n",
    "                break\n",
    "            f_i[n], f_i[res[0][0]] = f_i[res[0][0]], f_i[n]\n",
    "    c=list(zip(f_l,f_i))\n",
    "    random.shuffle(c)\n",
    "    f_l,f_i=zip(*c)\n",
    "    if flag==1:\n",
    "        f_l=[\"Dataset/Key/\"+f.split('/')[0]+'/Ann/'+f.split('/')[1] for f in f_l]\n",
    "        f_i=[\"Dataset/Key/\"+f.split('/')[0]+'/Image_spec/'+f.split('/')[1] for f in f_i]\n",
    "    images=[]\n",
    "    ann=[]\n",
    "    print(\"Processing the images...\")\n",
    "    for f in f_i:\n",
    "        h5f = h5py.File(f\"{f}\",'r')\n",
    "        b = h5f['d'][:]\n",
    "        images.append(np.asarray(b))\n",
    "        print(b.shape)\n",
    "    print(\"Processing the annotations\")\n",
    "    \n",
    "    for an in f_l:\n",
    "        \n",
    "        with open(an) as f:\n",
    "            ann.append(int(f.readlines()[0]))\n",
    "    test_x=np.asarray(images[0:math.ceil(len(f_i)*0.2)])\n",
    "    test_file=f_i[:math.ceil(len(f_i)*0.2)]\n",
    "    test_y=np.array(ann[0:math.ceil(len(f_i)*0.2)])\n",
    "    train_x=np.asarray(images[len(test_x):len(test_x)+math.ceil(len(f_i)*0.6)])\n",
    "    train_y=np.array(ann[len(test_x):len(test_x)+math.ceil(len(f_i)*0.6)])\n",
    "    val_x=np.asarray(images[len(test_x)+len(train_x):])\n",
    "    val_y=np.array(ann[len(test_x)+len(train_x):])\n",
    "    train_y = to_categorical(train_y, 24)\n",
    "    test_y = to_categorical(test_y, 24) \n",
    "    val_y= to_categorical(val_y, 24)\n",
    "    print(f\"Split a total of {len(f_i)} samples into three sets with {len(train_x)} training, {len(val_x)} validation and {len(test_x)} test samples.\")\n",
    "    return test_x,test_y,train_x,train_y,val_x,val_y,test_file\n",
    "\n",
    "\n",
    "x_test,y_test,x_train,y_train,x_val,y_val,test_file=split_train_test_validation(path_ann,path_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2v8Qygew6udY",
    "outputId": "2adc34f9-3bb9-4cf6-96c6-e016696daa83"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_3. Consider increasing the input size. Received input shape [None, 23, 1, 16] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-09a0f643b1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m model = tf.keras.Sequential([\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m215\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m    303\u001b[0m           \u001b[1;34mf'One of the dimensions in the output is <= 0 '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m           \u001b[1;34mf'due to downsampling in {self.name}. Consider '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_3. Consider increasing the input size. Received input shape [None, 23, 1, 16] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import Input\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, (5, 5), activation='relu', input_shape=(256, 40,1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(16, (5, 5), activation='relu',kernel_regularizer=keras.regularizers.l2(0.005)), \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(16, (5, 5), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (5, 5), activation='relu',kernel_regularizer=keras.regularizers.l2(0.005)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=keras.regularizers.l2(0.005)),\n",
    "    layers.Dense(24, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.055),loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=75, batch_size=132,validation_data=(x_val, y_val),callbacks=[es,mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9F5T1UH8Z8S"
   },
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xFgzOcFV8gtr",
    "outputId": "71de585b-7bec-4d05-ff66-eada66e77835"
   },
   "outputs": [],
   "source": [
    "#the accuracy is defined as the readme explain:\n",
    "#Relative fifth: error of 50% (Ex. Label: C major , Prediction: G major)\n",
    "#Relative minor/major: error of 75% (Ex. Label: C major, Prediction: A minor)\n",
    "#Parallel minor/major: error of 90% (Ex. Label: C major, Prediciotn: C minor) \n",
    "def get_accuracy(model, true_x, true_y): \n",
    "    res = model.predict(true_x)\n",
    "    res = np.argmax(res, axis=-1)\n",
    "    acc = 0\n",
    "    for i in range(len(true_y[:, 0])):\n",
    "        r=res[i]\n",
    "        t=np.where(true_y[i,:]==1)[0]\n",
    "        if r==t:\n",
    "          \n",
    "          acc+=1\n",
    "        elif r==(t+7)% (24//2):\n",
    "          acc+=0.5\n",
    "        elif r==(t-3) or r==(t+9)%24 or r==(t+3)%(24//2):\n",
    "          acc+=0.25\n",
    "        elif (r==(t+12)%24):\n",
    "          acc+=0.1\n",
    "        else:\n",
    "            pass\n",
    "    tot = len(true_y[:,0])\n",
    "    print('True - total', acc, tot)\n",
    "    print('acc: {}'.format((acc/tot)))\n",
    "\n",
    "    \n",
    "#This function is implemented in order to have the training dataset distinguished for the original dataset, indeed\n",
    "#the output are the ExtendedBallroom and Giantsteps dataset\n",
    "def get_dataset(label,img,test_file):\n",
    "  f_l=[f for f in listdir(\"Annotations\") if isfile(join(\"Annotations\", f))]\n",
    "  f_i=[f for f in listdir(\"Image_spec2\") if isfile(join(\"Image_spec2\", f))]\n",
    "  f_l= np.asarray(f_l)\n",
    "  f_i= np.asarray(f_i)\n",
    "  for n in range(f_l.shape[0]):\n",
    "    print(n)\n",
    "    while True:\n",
    "      s=splitext(f_l[n])[0]\n",
    "      if \"lerch\" in s:\n",
    "        s=s[:len(s)-6]\n",
    "      res=np.where(f_i==f\"{str(s)}.jpeg\")\n",
    "      if(n==res[0]):\n",
    "        break\n",
    "      f_i[n], f_i[res[0][0]] = f_i[res[0][0]], f_i[n]\n",
    "  c=list(zip(f_l,f_i))\n",
    "  giant_i=[]\n",
    "  gtzan_i=[]\n",
    "  gtzan_l=[]\n",
    "  giant_l=[]\n",
    "  lofi=\"LOFI\"\n",
    "  words=['blues','classical','country','disco','hiphop','jazz','metal','rock','reggae','pop']\n",
    "  for f in f_i:\n",
    "    if f in test_file: \n",
    "      if lofi in f:\n",
    "        idx=np.where(f_i == f)\n",
    "        giant_i.append(f)\n",
    "        giant_l.append(f_l[idx])\n",
    "      for w in words:\n",
    "        if w in f:\n",
    "          idx=np.where(f_i == f)\n",
    "          gtzan_i.append(f)\n",
    "          gtzan_l.append(f_l[idx])\n",
    "  gt_i=[]\n",
    "  gt_l=[]\n",
    "  gi_i=[]\n",
    "  gi_l=[]\n",
    "  for g1 in gtzan_i:\n",
    "    gt_i.append(np.asarray(ImageOps.grayscale(Image.open(f\"Image_spec2/{g1}\").resize((100,100)))))\n",
    "  for g2 in giant_i:  \n",
    "    gi_i.append(np.asarray(ImageOps.grayscale(Image.open(f\"Image_spec2/{g2}\").resize((100,100)))))\n",
    "  for g1 in gtzan_l:\n",
    "    with open(f\"Annotations/{g1[0]}\") as f:\n",
    "      gt_l.append(int(f.readlines()[0]))\n",
    "  for g2 in giant_l:\n",
    "    with open(f\"Annotations/{g2[0]}\") as f:\n",
    "      gi_l.append(int(f.readlines()[0]))\n",
    "  gt_i=np.asarray(gt_i)\n",
    "  gt_l=np.asarray(gt_l)\n",
    "  gi_i=np.asarray(gi_i)\n",
    "  gi_l=np.asarray(gi_l)\n",
    "  return gt_i,gt_l,gi_i,gi_l\n",
    "gtzan_i,gtzan_l,giant_i,giant_l=get_dataset(path_ann,path_images,test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(model,giant_i,giant_l)\n",
    "get_accuracy(model,gtzan_i,gtzan_l)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model for Key Estimation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
