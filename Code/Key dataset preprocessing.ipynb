{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebb7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir,mkdir\n",
    "from os.path import isfile, join, splitext,exists\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import sys\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from madmom.audio.filters import MelFilterbank \n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "path_giant_audio=\"Dataset/Key/GS/Audio\"\n",
    "path_giant_ann=\"Dataset/Key/GS/Ann\"\n",
    "path_giant_image=\"Dataset/Key/GS/Image_spec\"\n",
    "path_gtzan_audio=\"Dataset/Key/GTZAN/Audio\"\n",
    "path_gtzan_ann=\"Dataset/Key/GTZAN/Ann\"\n",
    "path_gtzan_image=\"Dataset/Key/GTZAN/Image_spec\"\n",
    "lst_name_chords=['A major','Bb major','B major','C major','Db major','D major','Eb major','E major','F major','Gb major','G major','Ab major','A minor','Bb minor','B minor','C minor','Db minor','D minor','Eb minor','E minor','F minor','Gb minor','G minor','Ab minor']\n",
    "lst_chords=range(len(lst_name_chords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aeb414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this line in order to download the giantsteps key dataset\n",
    "\n",
    "!git clone https://github.com/GiantSteps/giantsteps-key-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20010323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the folder for key dataset...\n"
     ]
    }
   ],
   "source": [
    "path=[path_giant_ann,path_gtzan_ann,path_gtzan_audio,path_giant_audio]\n",
    "def create_folder(path):\n",
    "    print(\"Creating the folder for key dataset...\")\n",
    "    for p in path:\n",
    "        list_path=p.split('/')\n",
    "        folder=list_path[0]\n",
    "        if not exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        for n in range(len(list_path)-1):\n",
    "            folder=folder+f\"/{list_path[n+1]}\"\n",
    "            if not exists(folder):\n",
    "                os.mkdir(folder)   \n",
    "                \n",
    "                \n",
    "\n",
    "create_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b242340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#please run the file audio \"audio_dl.sh\" in \"giantsetps-key-dataset\" folder before running this part\n",
    "\n",
    "def move_data_gs(path,dst_audio,dst_ann):\n",
    "    \n",
    "    path_ann=path+\"/annotations/key\"\n",
    "    onlyfiles = [f for f in listdir(path_ann) if isfile(join(path_ann, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(path_ann+f\"/{f}\",dst_ann+f\"/{f}\")\n",
    "    path_audio=path+\"/audio\"\n",
    "    new_path_audio=dst_audio\n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(path_audio+f\"/{f}\",dst_audio+f\"/{f}\")\n",
    "        \n",
    "\n",
    "move_data_gs('giantsteps-key-dataset',path_giant_audio,path_giant_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd18eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gtzan_key'...\n"
     ]
    }
   ],
   "source": [
    "#regarding the GTZAN project: download the dataset from the link \"http://opihi.cs.uvic.ca/sound/genres.tar.gz\"\n",
    "#please extract the file in the folder \"GTZAN\"\n",
    "#After that delete the file txt \"Delete This.txt\"\n",
    "!git clone \"https://github.com/alexanderlerch/gtzan_key.git\"\n",
    "def move_data_gtzan(path,dst_audio,dst_ann):\n",
    "    onlydir = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "    for d in onlydir:\n",
    "        onlydir2=[f for f in listdir(path+\"/\"+d) if os.path.isdir(join(path+\"/\"+d, f))]\n",
    "        for f in onlydir2:\n",
    "            onlyfiles=[t for t in listdir(path+\"/\"+d+\"/\"+f) if isfile(join(path+\"/\"+d+\"/\"+f, t)) if t.endswith('.wav')]\n",
    "            for t in onlyfiles:\n",
    "                os.rename(path+f\"/{d}/{f}/{t}\",dst_audio+f\"/{t}\")\n",
    "                \n",
    "    onlydir = [name for name in os.listdir(\"gtzan_key/gtzan_key/genres\") if os.path.isdir(os.path.join(\"gtzan_key/gtzan_key/genres\", name))]\n",
    "    for d in onlydir:\n",
    "        onlyfiles=[f for f in listdir(\"gtzan_key/gtzan_key/genres\"+\"/\"+d) if isfile(join(\"gtzan_key/gtzan_key/genres\"+\"/\"+d, f))]\n",
    "        for f in onlyfiles:\n",
    "            os.rename(\"gtzan_key/gtzan_key/genres\"+f\"/{d}/{f}\",dst_ann+f\"/{f}\")\n",
    "    os.remove(path_gtzan_ann+\"/disco.00055.pk\")\n",
    "move_data_gtzan(\"GTZAN\",path_gtzan_audio,path_gtzan_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2149713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_giant_audio=\"Dataset/Key/GS/Audio\"\n",
    "path_giant_ann=\"Dataset/Key/GS/Ann\"\n",
    "path_giant_image=\"Dataset/Key/GS/Image_spec\"\n",
    "path_gtzan_audio=\"Dataset/Key/GTZAN/Audio\"\n",
    "path_gtzan_ann=\"Dataset/Key/GTZAN/Ann\"\n",
    "path_gtzan_image=\"Dataset/Key/GTZAN/Image_spec\"\n",
    "lst_name_chords=['A major','Bb major','B major','C major','Db major','D major','Eb major','E major','F major','Gb major','G major','Ab major','A minor','Bb minor','B minor','C minor','Db minor','D minor','Eb minor','E minor','F minor','Gb minor','G minor','Ab minor']\n",
    "lst_chords=range(len(lst_name_chords))\n",
    "\n",
    "\n",
    "def convert_to_wav(path_audio):\n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    \n",
    "    #for each file, convert it into wav\n",
    "    for f in onlyfiles:\n",
    "        sound = AudioSegment.from_mp3(f\"{path_audio}/{f}\")\n",
    "        dst = f\"{path_audio}/{splitext(f)[0]}.wav\"\n",
    "        sound.export(dst, format=\"wav\")\n",
    "        os.remove(f\"{path_audio}/{f}\")\n",
    "        \n",
    "def convert_annotations(path_ann):\n",
    "    #it may happen that we have annotation written like 'db minor'. We need to convert it as a number\n",
    "    #It is adapted to the Dictionary of GTZAN, where tehre is only the Major and Minor scale ordered as the following list is\n",
    "    \n",
    "    onlyfiles = [f for f in listdir(path_ann) if isfile(join(path_ann, f))]\n",
    "    for f in onlyfiles:\n",
    "        a=open(f\"{path_ann}/{f}\",\"r\")\n",
    "        chord=a.readlines()\n",
    "        a.close()\n",
    "        numb_chord=lst_chords[lst_name_chords.index(chord[0])]\n",
    "        a=open(f\"{path_ann}/{splitext(f)[0]}.txt\",\"w\")\n",
    "        a.write(str(numb_chord))\n",
    "        a.close()\n",
    "\n",
    "#giantsteps annotations file have .key extensions, let's standardize it to a classic .txt file         \n",
    "def rename_key_file(path):\n",
    "    #I delete the key file for faster stuff\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(f\"{path}/{f}\",f\"{path}/{splitext(f)[0]}.txt\")\n",
    "        if \"lerch\" in f:\n",
    "            f2=((splitext(f)[0])[:len(f)-10])\n",
    "            os.rename(f\"{path}/{f}\",f\"{path}/{f2}.txt\")\n",
    "        \n",
    "def data_augmentation(path_audio,path_ann):\n",
    "    #1st data augmentation-> pitch shifting, by 2,-2,6,-6 semitones\n",
    "    f_audio = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    \n",
    "    for f in f_audio:\n",
    "        y, sr = librosa.load(f\"{path_audio}/{f}\")\n",
    "        lst_name_file_shifted=[\"2\",\"2n\",\"6\",\"6n\"]\n",
    "        lst_shift=[2,-2,6,-6]\n",
    "        \n",
    "        #memorize the chord\n",
    "        a=open(f\"{path_ann}/{splitext(f)[0]}.txt\",\"r\")\n",
    "        chord=a.readlines()\n",
    "        a.close()\n",
    "        for s in lst_shift:\n",
    "            #write the audio shifted\n",
    "            audio=librosa.effects.pitch_shift(y, sr, n_steps=s)\n",
    "            sf.write(f'{path_audio}/{lst_name_file_shifted[lst_shift.index(s)]}_{f}', audio, sr,'PCM_24')\n",
    "            #modify the ann\n",
    "            new_chord=lst_chords[(int(chord[0])+s) % len(lst_chords)]\n",
    "            a=open(f\"{path_ann}/{lst_name_file_shifted[lst_shift.index(s)]}_{splitext(f)[0]}.txt\",'w')\n",
    "            a.write(str(new_chord))\n",
    "            a.close()\n",
    "            \n",
    "    #2nd data augmentation -> divide the original audio in 15 sec audio, it is needed just this lenght in order to achieve some results\n",
    "    f_audio = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in f_audio:\n",
    "        y,sr=librosa.load(f\"{path_audio}/{f}\")\n",
    "        if len(y)>sr*15:\n",
    "            count=1\n",
    "            \n",
    "            #memorize the chord\n",
    "            a=open(f\"{path_ann}/{splitext(f)[0]}.txt\",\"r\")\n",
    "            bpm=a.readlines()\n",
    "            a.close()\n",
    "            \n",
    "            while True:\n",
    "                if(sr*15*count<=len(y)):\n",
    "                    \n",
    "                    y_new=y[sr*15*(count-1):sr*15*count]\n",
    "                    sf.write(f'{path_audio}/{splitext(f)[0]}_{count}.wav', y_new, sr,'PCM_24')\n",
    "                    if count==1: #rename the original file\n",
    "                        os.rename(f\"{path_ann}/{splitext(f)[0]}.txt\", f\"{path_ann}/{splitext(f)[0]}_{count}.txt\")\n",
    "                    else:\n",
    "                        a=open(f\"{path_ann}/{splitext(f)[0]}_{count}.txt\",\"w\")\n",
    "                        a.write(str(bpm[0]))\n",
    "                        a.close()\n",
    "                    count+=1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "            os.remove(f\"{path_audio}/{f}\")\n",
    "\n",
    "        \n",
    "rename_key_file(path_giant_ann)\n",
    "rename_key_file(path_gtzan_ann)\n",
    "convert_to_wav(path_giant_audio)\n",
    "convert_annotations(path_giant_ann)\n",
    "data_augmentation(path_giant_audio,path_giant_ann)\n",
    "data_augmentation(path_gtzan_audio,path_gtzan_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2166c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "def folder_images(path):\n",
    "    if not exists(path):\n",
    "        os.mkdir(path)\n",
    "#Preprocessing with the creation of log-melspectrogram\n",
    "def creation_spectrograms(path_audio,path_img):\n",
    "    \n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in onlyfiles:\n",
    "        y,sr=librosa.load(f\"{path_audio}/{f}\",sr=22050)\n",
    "        ps = librosa.feature.melspectrogram(y=y,n_fft=1024, hop_length=1024//2,sr=sr,power=1,n_mels=40, fmin=20, fmax=5000)\n",
    "        mels = np.log(ps + 1e-9)\n",
    "        mels = librosa.power_to_db(ps, ref=np.max)\n",
    "        #print(mels.shape)\n",
    "        mels_resized= resize(mels, (mels.shape[0], int(mels.shape[1] * 0.39629)),anti_aliasing=True)\n",
    "        #print(mels_resized.shape)\n",
    "        h5f = h5py.File(f\"{path_img}/{splitext(f)[0]}.h5\", 'w')\n",
    "        h5f.create_dataset(\"d\", data=mels_resized)\n",
    "        h5f.close()\n",
    "        \n",
    "folder_images(path_giant_image)\n",
    "folder_images(path_gtzan_image)\n",
    "creation_spectrograms(path_giant_audio,path_giant_image)\n",
    "creation_spectrograms(path_gtzan_audio,path_gtzan_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73883e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Dataset/Key/GS/Image_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-38cd90474fed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0monlyfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_giant_image\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_giant_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0monlyfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path_giant_image}/{f}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Dataset/Key/GS/Image_spec'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
