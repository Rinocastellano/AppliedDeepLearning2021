{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fab803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE PREPROCESSING DATASET TEMPO\n",
    "from zipfile import ZipFile\n",
    "import xml.etree.cElementTree as et\n",
    "from os import listdir,mkdir,system\n",
    "from os.path import isfile, join, splitext,exists\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import sys\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from madmom.audio.filters import MelFilterbank \n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "def unzip(path):\n",
    "    with ZipFile(path, 'r') as zipp:\n",
    "        print('Extracting all the files now...')\n",
    "        zipp.extractall()\n",
    "        print('Done!')\n",
    "        \n",
    "#Function that extracts the annotation from the xml file of ExtendedBallroom dataset and standardize\n",
    "#the annotations, indeed the result is having the folder \"Ann\" filled of txt files, containing each one the bpm of the related song\n",
    "def ext_ann(path_ann):\n",
    "    tree=et.parse('ext/extendedballroom_v1.1.xml')\n",
    "    root=tree.getroot()\n",
    "    for n in range(len(root)):\n",
    "        for x in root[n]:\n",
    "            a=open(f\"{path_ann}/{x.attrib['id']}.txt\",'w')\n",
    "            a.write(str(x.attrib['bpm']))\n",
    "            a.close()\n",
    "            \n",
    "\n",
    "#this function is used for the Giantsteps dataset that containes the annotation written as file .bpm, these files are standardized\n",
    "# as file .txt\n",
    "def rename_file(path):\n",
    "    #I delete the key file for faster stuff\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(f\"{path}/{f}\",f\"{path}/{splitext(f)[0]}.txt\")\n",
    "        \n",
    "        \n",
    "def convert_to_wav(path):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    #let's first create the directory for wav\n",
    "    #for each file, convert it into wav\n",
    "    for f in onlyfiles:\n",
    "        sound = AudioSegment.from_mp3(f\"{path}/{f}\")\n",
    "        dst = f\"{path}/{splitext(f)[0]}.wav\"\n",
    "        sound.export(dst, format=\"wav\")\n",
    "        os.remove(f\"{path}/{f}\")\n",
    "        \n",
    "\n",
    "path_giant_ann=\"Dataset/Tempo/GS/Ann\"\n",
    "path_giant_audio=\"Dataset/Tempo/GS/Audio\"\n",
    "path_giant_image=\"Dataset/Tempo/GS/Image_spec\"\n",
    "path_ext_ann=\"Dataset/Tempo/EXT/Ann\"\n",
    "path_ext_audio=\"Dataset/Tempo/EXT/Audio\"\n",
    "path_ext_image=\"Dataset/Tempo/EXT/Image_spec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3725811",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/GiantSteps/giantsteps-tempo-dataset.git\"\n",
    "#THEN RUN THE FILE \"audio_dl.sh\" in order to download the audio of Giantsteps dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=[path_giant_ann,path_ext_ann,path_giant_audio,path_ext_audio]\n",
    "def create_folder(path):\n",
    "    for p in path:\n",
    "        list_path=p.split('/')\n",
    "        folder=list_path[0]\n",
    "        if not exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        for n in range(len(list_path)-1):\n",
    "            print(folder)\n",
    "            folder=folder+f\"/{list_path[n+1]}\"\n",
    "            if not exists(folder):\n",
    "                os.mkdir(folder)   \n",
    "create_folder(path)\n",
    "\n",
    "#and fill all the data\n",
    "def move_data_gs(path,dst_audio,dst_ann):\n",
    "    \n",
    "    path_ann=path+\"/annotations_v2/tempo\"\n",
    "    onlyfiles = [f for f in listdir(path_ann) if isfile(join(path_ann, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(path_ann+f\"/{f}\",dst_ann+f\"/{f}\")\n",
    "    path_audio=path+\"/audio\"\n",
    "    new_path_audio=dst_audio\n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in onlyfiles:\n",
    "        os.rename(path_audio+f\"/{f}\",dst_audio+f\"/{f}\")\n",
    "        \n",
    "\n",
    "move_data_gs('giantsteps-tempo-dataset',path_giant_audio,path_giant_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ann(path_ext_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip(\"ext/extendedballroom_v1.1.zip\")\n",
    "os.rename(\"getExtendedBallroomDataset.py\",\"ext/getExtendedBallroomDataset.py\")\n",
    "os.rename(\"extendedballroom_v1.1.xml\",\"ext/extendedballroom_v1.1.xml\")\n",
    "#Then execute the file \"getExtendedBallroomDataset.py\" In order to download all the audio\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_EXT(path,dst_audio,dst_ann):\n",
    "    #move the audio\n",
    "    onlydir = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "    for d in onlydir:\n",
    "        onlyfiles=[f for f in listdir(path+\"/\"+d) if isfile(join(path+\"/\"+d, f))]\n",
    "        for f in onlyfiles:\n",
    "            os.rename(path+f\"/{d}/{f}\",dst_audio+f\"/{f}\")\n",
    "    #move the annotations\n",
    "    ext_ann(dst_ann)\n",
    "move_data_EXT(\"ext\",path_ext_audio,path_ext_ann)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_wav(path_ext_audio)\n",
    "convert_to_wav(path_giant_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b479eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is preferable to have everything standardized, even the extension of the annotation\n",
    "rename_file(path_giant_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6544f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_data(path_audio,path_ann):\n",
    "    #1st data augmentation, using librosa let's accelerate/decelerate the speed, consequently the bpm\n",
    "    #by shifting to right and left 1/5 the original speed\n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in onlyfiles:\n",
    "        a=open(f\"{path_ann}/{splitext(f)[0]}.txt\",\"r\")\n",
    "        bpm=a.readlines()\n",
    "        a.close()\n",
    "        y,sr=librosa.load(f\"{path_audio}/{f}\")\n",
    "        y_s = librosa.effects.time_stretch(y, 1.2)\n",
    "        y_f =librosa.effects.time_stretch(y, 0.8)\n",
    "        sf.write(f'{path_audio}/f_{f}', y_f, sr,'PCM_24')\n",
    "        sf.write(f'{path_audio}/s_{f}', y_s, sr,'PCM_24')\n",
    "        a=open(f\"{path_ann}/f_{splitext(f)[0]}.txt\",\"w\")\n",
    "        a.write(str(float(bpm[0])*2))\n",
    "        a.close()\n",
    "        a=open(f\"{path_ann}/s_{splitext(f)[0]}.txt\",\"w\")\n",
    "        a.write(str(float(bpm[0])/2))\n",
    "        a.close()\n",
    "    #2nd augmentation: cut the long audio into many pieces of audio\n",
    "    #it is needed just 15 sec of audio \n",
    "    #in this way we standardize all the audio in the time frame (15 sec)\n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    for f in onlyfiles:\n",
    "        y,sr=librosa.load(f\"{path_audio}/{f}\")\n",
    "        if len(y)>sr*15:\n",
    "            count=1\n",
    "            \n",
    "            #memorize the chord\n",
    "            a=open(f\"{path_ann}/{splitext(f)[0]}.txt\",\"r\")\n",
    "            bpm=a.readlines()\n",
    "            a.close()\n",
    "            \n",
    "            while True:\n",
    "                if(sr*15*count<=len(y)):\n",
    "                    \n",
    "                    y_new=y[sr*15*(count-1):sr*15*count]\n",
    "                    sf.write(f'{path_audio}/{splitext(f)[0]}_{count}.wav', y_new, sr,'PCM_24')\n",
    "                    if count==1: #rename the original file\n",
    "                        os.rename(f\"{path_ann}/{splitext(f)[0]}.txt\", f\"{path_ann}/{splitext(f)[0]}_{count}.txt\")\n",
    "                    else:\n",
    "                        a=open(f\"{path_ann}/{splitext(f)[0]}_{count}.txt\",\"w\")\n",
    "                        a.write(str(bpm[0]))\n",
    "                        a.close()\n",
    "                    count+=1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "            os.remove(f\"{path_audio}/{f}\")\n",
    "            \n",
    "    \n",
    "augmentation_data(path_giant_audio,path_giant_ann)\n",
    "augmentation_data(path_ext_audio,path_ext_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1136461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "def create_image_spec(path_audio,path_img):\n",
    "    #A good representation for the audio is in its mel-spectrogram form\n",
    "    #It is decided to compute the log_mel_spectrgram of each audio \n",
    "    onlyfiles = [f for f in listdir(path_audio) if isfile(join(path_audio, f))]\n",
    "    if not exists(path_img):\n",
    "        os.mkdir(path_img)\n",
    "    for f in onlyfiles:\n",
    "        \n",
    "        if not exists(f\"{path_img}/{splitext(f)[0]}.jpeg\"):\n",
    "            y,sr=librosa.load(f\"{path_audio}/{f}\",sr=22050)\n",
    "            ps = librosa.feature.melspectrogram(y=y,n_fft=1024, hop_length=1024//2,sr=sr,power=1,n_mels=40, fmin=20, fmax=5000)\n",
    "            mels = np.log(ps + 1e-9)\n",
    "            mels = librosa.power_to_db(ps, ref=np.max)\n",
    "            mels_resized= resize(mels, (mels.shape[0], int(mels.shape[1] * 0.39629)),anti_aliasing=True)\n",
    "            #print(mels_resized.shape)\n",
    "            h5f = h5py.File(f\"{path_img}/{splitext(f)[0]}.h5\", 'w')\n",
    "            h5f.create_dataset(\"d\", data=mels_resized)\n",
    "            h5f.close()\n",
    "            \n",
    "create_image_spec(path_giant_audio,path_giant_image)\n",
    "create_image_spec(path_ext_audio,path_ext_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
