{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "CHQNDiPNwkEx",
    "outputId": "ce0cac27-5d70-4c74-b30e-d366eda9d1c2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras import Input\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6rBgg-dw_Q-",
    "outputId": "aaf7134b-63af-4126-de1e-880a7d0ed455"
   },
   "outputs": [],
   "source": [
    "#If you didn't run the previous code that do the preprocessing -> run this part of code please\n",
    "#DATASET USED FOR THE MODEL FOR TEMPO ESTIMATION, IT'S JUST PREPROCESSED\n",
    "!gdown --id 1laAPu4rWL--uQqImUVLRucxX45WioDo6\n",
    "!gdown --id 1dss_W5QL0y-C3LxuCHWO72FnXOq1nc3y\n",
    "\n",
    "path_images=[\"Image_spec_t/\"]\n",
    "path_ann=[\"Ann_bpm/\"]\n",
    "from zipfile import ZipFile\n",
    "for p in path:\n",
    "    with ZipFile(p, 'r') as zipp:\n",
    "        # printing all the contents of the zip file\n",
    "        #zip.printdir()\n",
    "        print('Extracting all the files now...')\n",
    "        zipp.extractall()\n",
    "        print('Done!')\n",
    "flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzS0XxTvw_8Z"
   },
   "outputs": [],
   "source": [
    "#If you have done the preprocessing using the previous notebook, please run this part of code\n",
    "path_images=[\"Dataset/Tempo/GS/Image_spec\",\"Dataset/Tempo/EXT/Image_spec\"]\n",
    "path_ann=[\"Dataset/Tempo/GS/Ann\",\"Dataset/Tempo/EXT/Ann\"]\n",
    "flag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMQ6WLmUx2HB",
    "outputId": "abf4726e-72b6-48b1-d0b5-409ac96a5c00"
   },
   "outputs": [],
   "source": [
    "def split_train_test_validation(path_label,path_img):\n",
    "    f_l=[]\n",
    "    f_i=[]\n",
    "    for i,l in zip(path_img,path_label):\n",
    "        f_l.extend([os.path.join(root, name) for root, dirs, files in os.walk(l) for name in files if name.endswith((\".txt\"))])\n",
    "        f_i.extend([os.path.join(root, name) for root, dirs, files in os.walk(i) for name in files if name.endswith((\".jpeg\"))])\n",
    "\n",
    "        f_l=[os.path.join(f.split('/')[1],f.split('/')[2]) for f in f_l]\n",
    "        f_i=[os.path.join(f.split('/')[1],f.split('/')[2]) for f in f_i]\n",
    "\n",
    "    f_l= np.asarray(f_l)\n",
    "    f_i= np.asarray(f_i)\n",
    "    print(\"Sorting both images and annotations...\")\n",
    "    for n in range(f_l.shape[0]):\n",
    "    while True:\n",
    "      s=splitext(f_l[n])[0]\n",
    "      if \"lerch\" in s:\n",
    "        s=s[:len(s)-6]\n",
    "      res=np.where(f_i==f\"{str(s)}.jpeg\")\n",
    "      if(n==res[0]):\n",
    "        break\n",
    "      f_i[n], f_i[res[0][0]] = f_i[res[0][0]], f_i[n]\n",
    "    c=list(zip(f_l,f_i))\n",
    "    random.shuffle(c)\n",
    "    f_l,f_i=zip(*c)\n",
    "    images=[]\n",
    "    ann=[]\n",
    "    print(\"Processing the images...\")\n",
    "    for f in f_i:\n",
    "    images.append(np.asarray(ImageOps.grayscale(Image.open(f\"Image_spec_t/{f}\").resize((40,512)))))\n",
    "    print(\"Processing the annotations\")\n",
    "    for an in f_l:\n",
    "    with open(f\"Ann_bpm/{an}\") as f:\n",
    "      bpm=int(float(f.readlines()[0]))\n",
    "      ann.append(bpm)\n",
    "\n",
    "\n",
    "    min_annotation=min(ann)\n",
    "    #This is a big assumption in order to avoid the wrong annotations setted as 0.\n",
    "    #It is encountered 5-6 in a dataset of 10 thousands, I putted them in an average bpm\n",
    "    #that usually lives between 90 and 120 bpm for pop-music\n",
    "    while min_annotation==0:\n",
    "        ann[ann.index(min_annotation)]=100\n",
    "        min_annotation=min(ann)\n",
    "    MIN_BPM=min_annotation\n",
    "    max_annotation=max(ann)-min(ann)\n",
    "    print(f\"Minimum bpm found is {min_annotation}, the maximum is {max_annotation}\")\n",
    "    ann=[x-min_annotation  for x in ann]\n",
    "    test_x=np.asarray(images[0:math.ceil(len(f_i)*0.2)])/255\n",
    "    test_file=f_i[:math.ceil(len(f_i)*0.2)]\n",
    "    test_y=np.array(ann[0:math.ceil(len(f_i)*0.2)])\n",
    "    train_x=np.asarray(images[len(test_x):len(test_x)+math.ceil(len(f_i)*0.6)])/255\n",
    "    train_y=np.array(ann[len(test_x):len(test_x)+math.ceil(len(f_i)*0.6)])\n",
    "    val_x=np.asarray(images[len(test_x)+len(train_x):])/255\n",
    "    val_y=np.array(ann[len(test_x)+len(train_x):])\n",
    "    train_y = to_categorical(train_y, max_annotation+1)\n",
    "    test_y = to_categorical(test_y, max_annotation+1) \n",
    "    print(max_annotation)\n",
    "    print(val_y)\n",
    "    val_y= to_categorical(val_y, max_annotation+1)\n",
    "    print(f\"Split a total of {len(f_i)} samples into three sets with {len(train_x)} training, {len(val_x)} validation and {len(test_x)} test samples.\")\n",
    "    return test_x,test_y,train_x,train_y,val_x,val_y,test_file,MIN_BPM\n",
    "\n",
    "\n",
    "x_test,y_test,x_train,y_train,x_val,y_val,test_file,MIN_BPM=split_train_test_validation(path_ann,path_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7cWV_wlH13J9",
    "outputId": "d88bac99-4232-4bf1-a620-bc62722c2c38"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, (5, 5), activation='relu', input_shape=(512, 40,1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (5, 5), activation='relu'), \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (5, 5), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    tf.keras.layers.Reshape(target_shape=(-1,32), name='reshape'),           \n",
    "    layers.Bidirectional(layers.LSTM(32, return_sequences=True,activation='tanh')),\n",
    "    layers.Bidirectional(layers.LSTM(32, return_sequences=True,activation='tanh')),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(153,activation='softmax')\n",
    "    \n",
    "])\n",
    "model.build((512,40))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.055),loss='categorical_crossentropy',metrics=['acc'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "history = model.fit(x_train, y_train, epochs=75, batch_size=99,validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBL4fEHm2L3F"
   },
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "pmIZWPAj2MkD",
    "outputId": "8f134928-2b78-47b1-ad26-33cba3e945ca"
   },
   "outputs": [],
   "source": [
    "#As explained in the readme, the accuracy for tempo estimation is stated as follows:\n",
    "#if the Tempo is doubled or halfed, error of 50% (Ex. Label: 80 BPM, Prediction: 160 BPM)\n",
    "#if the Tempo is between a tollerance interval, error of 0% (Ex. Label: 80 BPM, Prediction: 82 BPM (Tolerance of 8%))\n",
    "def get_accuracy(model, true_x, true_y): \n",
    "    res = model.predict(true_x)\n",
    "    res = np.argmax(res, axis=-1)\n",
    "    acc = 0\n",
    "    tol=0.08\n",
    "    for i in range(len(true_y)):\n",
    "        r=res[i]\n",
    "        t=true_y[i]\n",
    "        if r>t-(t*tol) and r<t+(t*tol):\n",
    "          acc+=1\n",
    "        elif (r>2*t-(t*tol) and r<2*t+(t*tol)) or (r>t//2-(t*tol) and r<t//2+(t*tol)):\n",
    "          acc+=0.5\n",
    "        else:\n",
    "            pass\n",
    "    tot = len(true_y)\n",
    "    print('acc0 : {}'.format((acc0/tot)))\n",
    "    print('acc1 : {}'.format((acc1/tot)))\n",
    "    print('acc2 : {}'.format((acc2/tot)))\n",
    "\n",
    "#This function is implemented in order to have the training dataset distinguished for the original dataset, indeed\n",
    "#the output are the ExtendedBallroom and Giantsteps dataset\n",
    "def get_training_dataset(label,img,test_file):\n",
    "  f_l=[]\n",
    "  f_i=[]\n",
    "  for i,l in zip(img,label):\n",
    "    f_l.extend([os.path.join(root, name) for root, dirs, files in os.walk(l) for name in files if name.endswith((\".txt\"))])\n",
    "    f_i.extend([os.path.join(root, name) for root, dirs, files in os.walk(i) for name in files if name.endswith((\".jpeg\"))])\n",
    "  f_l= np.asarray(f_l)\n",
    "  f_i= np.asarray(f_i)\n",
    "  for n in range(f_l.shape[0]):\n",
    "    while True:\n",
    "      s=splitext(f_l[n])[0]\n",
    "      if \"lerch\" in s:\n",
    "        s=s[:len(s)-6]\n",
    "      res=np.flatnonzero(np.core.defchararray.find(f_i,f\"{str(s).split('/')[-1]}\")!=-1)\n",
    "      if(n==res[0]):\n",
    "        break\n",
    "      f_i[n], f_i[res[0]] = f_i[res[0]], f_i[n]\n",
    "  c=list(zip(f_l,f_i))\n",
    "  giant_i=[]\n",
    "  ext_i=[]\n",
    "  ext_l=[]\n",
    "  giant_l=[]\n",
    "  lofi=\"LOFI\"\n",
    "  \n",
    "  for f in f_i:\n",
    "    if f in test_file: \n",
    "      if lofi in f:\n",
    "        idx=np.where(f_i == f)\n",
    "        giant_i.append(f)\n",
    "        giant_l.append(f_l[idx])\n",
    "      else:\n",
    "        idx=np.where(f_i == f)\n",
    "        ext_i.append(f)\n",
    "        ext_l.append(f_l[idx])\n",
    "  e_i=[]\n",
    "  e_l=[]\n",
    "  gi_i=[]\n",
    "  gi_l=[]\n",
    "  for g1 in ext_i:\n",
    "    e_i.append(np.asarray(ImageOps.grayscale(Image.open(f\"Image_spec_t/{g1}\").resize((40,512))))/255)\n",
    "  for g2 in giant_i:  \n",
    "    gi_i.append(np.asarray(ImageOps.grayscale(Image.open(f\"Image_spec_t/{g2}\").resize((40,512))))/255)\n",
    "  for g1 in ext_l:\n",
    "    with open(f\"Ann_bpm/{g1[0]}\") as f:\n",
    "      e_l.append(int(float(f.readlines()[0])))\n",
    "  for g2 in giant_l:\n",
    "    with open(f\"Ann_bpm/{g2[0]}\") as f:\n",
    "      gi_l.append(int(float(f.readlines()[0])))\n",
    "  e_i=np.asarray(e_i)\n",
    "  e_l=np.asarray(e_l)\n",
    "  gi_i=np.asarray(gi_i)\n",
    "  gi_l=np.asarray(gi_l)\n",
    "  return e_i,e_l,gi_i,gi_l\n",
    "  \n",
    "e_i,e_l,giant_i,giant_l=get_dataset(path_ann,path_images,test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(model,e_i,e_l)\n",
    "get_accuracy(model,giant_l,giant_i)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model for Tempo Estimation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
